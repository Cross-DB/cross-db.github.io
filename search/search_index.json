{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"community/","text":"Community \u00b6 Discussion \u00b6 Issue \u00b6 Requirement \u00b6","title":"Community"},{"location":"community/#community","text":"","title":"Community"},{"location":"community/#discussion","text":"","title":"Discussion"},{"location":"community/#issue","text":"","title":"Issue"},{"location":"community/#requirement","text":"","title":"Requirement"},{"location":"connector/","text":"Connector \u00b6 TBD","title":"Connector"},{"location":"connector/#connector","text":"TBD","title":"Connector"},{"location":"about/privacy/","text":"Privacy Notice \u00b6 Introduction \u00b6 CrossDB Software has designed its website so that, in general, you can browse the CrossDB website without being asked for any personal information. Exceptions to this are when you specifically ask for information, request an evaluation copy of our software or download CrossDB trial software. This policy covers how CrossDB Software treats personal information that CrossDB may collect and receive via the CrossDB website. Your use of the CrossDB website constitutes acceptance of and agreement with the CrossDB Software Privacy Policy. CrossDB reserves the right to change the CrossDB Software Privacy Policy at any time without notice. Information collection and use \u00b6 CrossDB collects personal information when you request for information, request an evaluation of our software or when you download trial software. This information includes information about you such as name, business name and address, telephone and fax numbers, email address, operating system, and hardware environment. Providing information is voluntary. You may provide this information by filling out an on-line form, by email or other communication to CrossDB. However, you may not receive the product information, software evaluation or downloads if you choose not to provide the requested information. CrossDB Software's use of the information you provided will be to send you the information that you requested. CrossDB Software may also use the information to provide you with additional information about our products and services or market research. The information may be used to follow up with you regarding information supplied, software you downloaded or evaluated. CrossDB does not sell information collected from users of CrossDB website to other organizations. CrossDB may share the information collected with its subsidiaries and its affiliates such as partners and distributors. General Information \u00b6 CrossDB web servers record standard information about CrossDB Web accesses such as IP addresses, your server name, browser type, etc. when you visit our website. CrossDB uses this for information about usage at CrossDB Software's website. The information submitted to CrossDB Software via the Web may be processed, stored and used outside the country where it was submitted. Links to third party websites are provided for your convenience. By using these links, you will no longer be on the CrossDB Software website and the CrossDB Software Privacy Policy will no longer apply. Contact us \u00b6 If you have any question about the information you provided to us or about the CrossDB Software Privacy Policy, please contact us at wang_junchuan@163.com","title":"Privacy"},{"location":"about/privacy/#privacy-notice","text":"","title":"Privacy Notice"},{"location":"about/privacy/#introduction","text":"CrossDB Software has designed its website so that, in general, you can browse the CrossDB website without being asked for any personal information. Exceptions to this are when you specifically ask for information, request an evaluation copy of our software or download CrossDB trial software. This policy covers how CrossDB Software treats personal information that CrossDB may collect and receive via the CrossDB website. Your use of the CrossDB website constitutes acceptance of and agreement with the CrossDB Software Privacy Policy. CrossDB reserves the right to change the CrossDB Software Privacy Policy at any time without notice.","title":"Introduction"},{"location":"about/privacy/#information-collection-and-use","text":"CrossDB collects personal information when you request for information, request an evaluation of our software or when you download trial software. This information includes information about you such as name, business name and address, telephone and fax numbers, email address, operating system, and hardware environment. Providing information is voluntary. You may provide this information by filling out an on-line form, by email or other communication to CrossDB. However, you may not receive the product information, software evaluation or downloads if you choose not to provide the requested information. CrossDB Software's use of the information you provided will be to send you the information that you requested. CrossDB Software may also use the information to provide you with additional information about our products and services or market research. The information may be used to follow up with you regarding information supplied, software you downloaded or evaluated. CrossDB does not sell information collected from users of CrossDB website to other organizations. CrossDB may share the information collected with its subsidiaries and its affiliates such as partners and distributors.","title":"Information collection and use"},{"location":"about/privacy/#general-information","text":"CrossDB web servers record standard information about CrossDB Web accesses such as IP addresses, your server name, browser type, etc. when you visit our website. CrossDB uses this for information about usage at CrossDB Software's website. The information submitted to CrossDB Software via the Web may be processed, stored and used outside the country where it was submitted. Links to third party websites are provided for your convenience. By using these links, you will no longer be on the CrossDB Software website and the CrossDB Software Privacy Policy will no longer apply.","title":"General Information"},{"location":"about/privacy/#contact-us","text":"If you have any question about the information you provided to us or about the CrossDB Software Privacy Policy, please contact us at wang_junchuan@163.com","title":"Contact us"},{"location":"about/refund/","text":"Refund Policy \u00b6 Thank you for buying CrossDB Embedded Database! We offer refund and/or exchange within the first 30 days of your purchase, if 30 days have passed since your purchase, you will not be offered a refund and/or exchange of any kind.","title":"Refund"},{"location":"about/refund/#refund-policy","text":"Thank you for buying CrossDB Embedded Database! We offer refund and/or exchange within the first 30 days of your purchase, if 30 days have passed since your purchase, you will not be offered a refund and/or exchange of any kind.","title":"Refund Policy"},{"location":"about/terms/","text":"Terms of Service \u00b6 CrossDB provides this Website for your information and use, subject to the terms set forth below. By accessing this Website, you agree to accept the following terms. General terms \u00b6 In no event will CrossDB be liable for any damages including, without limitation, indirect, incidental, consequential, special or exemplary damages, that arise out of or relate to the use of or inability to use the CrossDB Website, even if CrossDB has been advised of the possibility of such damages. Any and all information provided on CrossDB\u2019s Website is provided \u201cas is,\u201d with no warranty as to accuracy or content. CrossDB does not adopt or endorse the views of any third party Websites linked to or from the CrossDB Website. CrossDB reserves the right to change, modify, add or remove any of these terms at any time.","title":"Terms"},{"location":"about/terms/#terms-of-service","text":"CrossDB provides this Website for your information and use, subject to the terms set forth below. By accessing this Website, you agree to accept the following terms.","title":"Terms of Service"},{"location":"about/terms/#general-terms","text":"In no event will CrossDB be liable for any damages including, without limitation, indirect, incidental, consequential, special or exemplary damages, that arise out of or relate to the use of or inability to use the CrossDB Website, even if CrossDB has been advised of the possibility of such damages. Any and all information provided on CrossDB\u2019s Website is provided \u201cas is,\u201d with no warranty as to accuracy or content. CrossDB does not adopt or endorse the views of any third party Websites linked to or from the CrossDB Website. CrossDB reserves the right to change, modify, add or remove any of these terms at any time.","title":"General terms"},{"location":"appendix/changelog/","text":"Changelog \u00b6 TBD \u00b6","title":"Changelog"},{"location":"appendix/changelog/#changelog","text":"","title":"Changelog"},{"location":"appendix/changelog/#tbd","text":"","title":"TBD"},{"location":"appendix/faq/","text":"FAQ \u00b6 TBD \u00b6","title":"FAQ"},{"location":"appendix/faq/#faq","text":"","title":"FAQ"},{"location":"appendix/faq/#tbd","text":"","title":"TBD"},{"location":"appendix/internals/","text":"Internals \u00b6 Limits \u00b6 DB Files Structure \u00b6 Data Orgnization \u00b6 Hash Index Data Structure \u00b6 RBTree Index Data Structure \u00b6","title":"Internals"},{"location":"appendix/internals/#internals","text":"","title":"Internals"},{"location":"appendix/internals/#limits","text":"","title":"Limits"},{"location":"appendix/internals/#db-files-structure","text":"","title":"DB Files Structure"},{"location":"appendix/internals/#data-orgnization","text":"","title":"Data Orgnization"},{"location":"appendix/internals/#hash-index-data-structure","text":"","title":"Hash Index Data Structure"},{"location":"appendix/internals/#rbtree-index-data-structure","text":"","title":"RBTree Index Data Structure"},{"location":"appendix/reference/","text":"Reference \u00b6 TBD \u00b6","title":"Reference"},{"location":"appendix/reference/#reference","text":"","title":"Reference"},{"location":"appendix/reference/#tbd","text":"","title":"TBD"},{"location":"best-practice/","text":"Best Practice \u00b6 ISSU \u00b6 Monolithic App \u00b6 Persistency Storage \u00b6 Event Loop \u00b6 Distribute Config \u00b6 Distribute Dynamic Data \u00b6 HA Replication \u00b6 Persistency Storage \u00b6 Collect Status \u00b6 Collect Statistics \u00b6 Collect Logs \u00b6 Large Scale System \u00b6 TechLog \u00b6 Unite Test \u00b6","title":"Best Practice"},{"location":"best-practice/#best-practice","text":"","title":"Best Practice"},{"location":"best-practice/#issu","text":"","title":"ISSU"},{"location":"best-practice/#monolithic-app","text":"","title":"Monolithic App"},{"location":"best-practice/#persistency-storage","text":"","title":"Persistency Storage"},{"location":"best-practice/#event-loop","text":"","title":"Event Loop"},{"location":"best-practice/#distribute-config","text":"","title":"Distribute Config"},{"location":"best-practice/#distribute-dynamic-data","text":"","title":"Distribute Dynamic Data"},{"location":"best-practice/#ha-replication","text":"","title":"HA Replication"},{"location":"best-practice/#persistency-storage_1","text":"","title":"Persistency Storage"},{"location":"best-practice/#collect-status","text":"","title":"Collect Status"},{"location":"best-practice/#collect-statistics","text":"","title":"Collect Statistics"},{"location":"best-practice/#collect-logs","text":"","title":"Collect Logs"},{"location":"best-practice/#large-scale-system","text":"","title":"Large Scale System"},{"location":"best-practice/#techlog","text":"","title":"TechLog"},{"location":"best-practice/#unite-test","text":"","title":"Unite Test"},{"location":"blog/","text":"Blog \u00b6 TBD \u00b6","title":"Blog"},{"location":"blog/#blog","text":"","title":"Blog"},{"location":"blog/#tbd","text":"","title":"TBD"},{"location":"blog/2022/pp-oo-db/","text":"TBD \u00b6","title":"TBD"},{"location":"blog/2022/pp-oo-db/#tbd","text":"","title":"TBD"},{"location":"c-orm/orm-api/","text":"ORM API \u00b6 Record API \u00b6 Cursor API \u00b6","title":"ORM API"},{"location":"c-orm/orm-api/#orm-api","text":"","title":"ORM API"},{"location":"c-orm/orm-api/#record-api","text":"","title":"Record API"},{"location":"c-orm/orm-api/#cursor-api","text":"","title":"Cursor API"},{"location":"c-orm/overview/","text":"Overview \u00b6 TBD \u00b6","title":"Overview"},{"location":"c-orm/overview/#overview","text":"","title":"Overview"},{"location":"c-orm/overview/#tbd","text":"","title":"TBD"},{"location":"c-orm/schema/","text":"Schema \u00b6 Basic \u00b6 Enum \u00b6 Bitfield \u00b6 Array \u00b6 Nested Struct \u00b6 Union \u00b6 Schema Guide \u00b6 ISSU \u00b6","title":"Schema"},{"location":"c-orm/schema/#schema","text":"","title":"Schema"},{"location":"c-orm/schema/#basic","text":"","title":"Basic"},{"location":"c-orm/schema/#enum","text":"","title":"Enum"},{"location":"c-orm/schema/#bitfield","text":"","title":"Bitfield"},{"location":"c-orm/schema/#array","text":"","title":"Array"},{"location":"c-orm/schema/#nested-struct","text":"","title":"Nested Struct"},{"location":"c-orm/schema/#union","text":"","title":"Union"},{"location":"c-orm/schema/#schema-guide","text":"","title":"Schema Guide"},{"location":"c-orm/schema/#issu","text":"","title":"ISSU"},{"location":"fkey-trigger/cascade-trigger/","text":"Cascade Trigger \u00b6 Reliability \u00b6 Robust \u00b6 Falut Tolerent \u00b6","title":"Cascade Trigger"},{"location":"fkey-trigger/cascade-trigger/#cascade-trigger","text":"","title":"Cascade Trigger"},{"location":"fkey-trigger/cascade-trigger/#reliability","text":"","title":"Reliability"},{"location":"fkey-trigger/cascade-trigger/#robust","text":"","title":"Robust"},{"location":"fkey-trigger/cascade-trigger/#falut-tolerent","text":"","title":"Falut Tolerent"},{"location":"fkey-trigger/data-driven/","text":"Data-Driven \u00b6 Unit Test \u00b6","title":"Data-Driven"},{"location":"fkey-trigger/data-driven/#data-driven","text":"","title":"Data-Driven"},{"location":"fkey-trigger/data-driven/#unit-test","text":"","title":"Unit Test"},{"location":"fkey-trigger/foreign-key/","text":"Foreign Trigger \u00b6 Map Table \u00b6 Reference with Given value \u00b6 Defer Delete \u00b6 Cascase \u00b6 Restrict \u00b6 Zero value \u00b6 No Action \u00b6","title":"Foreign Trigger"},{"location":"fkey-trigger/foreign-key/#foreign-trigger","text":"","title":"Foreign Trigger"},{"location":"fkey-trigger/foreign-key/#map-table","text":"","title":"Map Table"},{"location":"fkey-trigger/foreign-key/#reference-with-given-value","text":"","title":"Reference with Given value"},{"location":"fkey-trigger/foreign-key/#defer-delete","text":"","title":"Defer Delete"},{"location":"fkey-trigger/foreign-key/#cascase","text":"","title":"Cascase"},{"location":"fkey-trigger/foreign-key/#restrict","text":"","title":"Restrict"},{"location":"fkey-trigger/foreign-key/#zero-value","text":"","title":"Zero value"},{"location":"fkey-trigger/foreign-key/#no-action","text":"","title":"No Action"},{"location":"fkey-trigger/overview/","text":"Overview \u00b6 TBD \u00b6","title":"Overview"},{"location":"fkey-trigger/overview/#overview","text":"","title":"Overview"},{"location":"fkey-trigger/overview/#tbd","text":"","title":"TBD"},{"location":"fkey-trigger/trigger/","text":"Trigger \u00b6 Reliability \u00b6 Robust \u00b6 Falut Tolerent \u00b6","title":"Trigger"},{"location":"fkey-trigger/trigger/#trigger","text":"","title":"Trigger"},{"location":"fkey-trigger/trigger/#reliability","text":"","title":"Reliability"},{"location":"fkey-trigger/trigger/#robust","text":"","title":"Robust"},{"location":"fkey-trigger/trigger/#falut-tolerent","text":"","title":"Falut Tolerent"},{"location":"product/buy/","text":"Buy on Paddle","title":"How to Buy"},{"location":"product/buy2/","text":"Product List \u00b6 .cdb-arrow { font-size: 26px; color: #81d742; } .button { color: #fff; background-color: #1e73be; font-family: \"Lato\",sans-serif; font-weight: 400; line-height: 1.2; line-height: 45px; min-height: 45px; font-size: 18px; text-transform: none; border: 1px solid #165389; border-radius: 4px; padding: 0 40px; cursor: pointer; } .button:hover { color: #000; background-color: #81d742; border: 1px solid #63b526; } Buy CrossDB Windows x64 for Server \u00b6 Primary Advanced Professional Enterprise Buy CrossDB Linux x64 for Server \u00b6 Primary Advanced Professional Enterprise Buy CrossDB Linux x64 for Embedded System(1000devices) \u00b6 Primary Advanced Professional Enterprise Buy CrossDB Linux arm64 for Embedded System (1000devices) \u00b6 Primary Advanced Professional Enterprise CrossDB Windows x64 Professional Version from Paddle \u00b6 Paddle.Setup({ vendor: 168148 }); Buy Now! We also have Volume Discounts when you buy. If you need more licenses than shown here, please contact us for a quote.","title":"Popup Buy"},{"location":"product/buy2/#product-list","text":".cdb-arrow { font-size: 26px; color: #81d742; } .button { color: #fff; background-color: #1e73be; font-family: \"Lato\",sans-serif; font-weight: 400; line-height: 1.2; line-height: 45px; min-height: 45px; font-size: 18px; text-transform: none; border: 1px solid #165389; border-radius: 4px; padding: 0 40px; cursor: pointer; } .button:hover { color: #000; background-color: #81d742; border: 1px solid #63b526; }","title":"Product List"},{"location":"product/buy2/#buy-crossdb-windows-x64-for-server","text":"Primary Advanced Professional Enterprise","title":"Buy CrossDB Windows x64 for Server"},{"location":"product/buy2/#buy-crossdb-linux-x64-for-server","text":"Primary Advanced Professional Enterprise","title":"Buy CrossDB Linux x64 for Server"},{"location":"product/buy2/#buy-crossdb-linux-x64-for-embedded-system1000devices","text":"Primary Advanced Professional Enterprise","title":"Buy CrossDB Linux x64 for Embedded System(1000devices)"},{"location":"product/buy2/#buy-crossdb-linux-arm64-for-embedded-system-1000devices","text":"Primary Advanced Professional Enterprise","title":"Buy CrossDB Linux arm64 for Embedded System (1000devices)"},{"location":"product/buy2/#crossdb-windows-x64-professional-version-from-paddle","text":"Paddle.Setup({ vendor: 168148 }); Buy Now! We also have Volume Discounts when you buy. If you need more licenses than shown here, please contact us for a quote.","title":"CrossDB Windows x64 Professional Version from Paddle"},{"location":"product/buy3/","text":"TBD \u00b6","title":"Embedded Buy"},{"location":"product/buy3/#tbd","text":"","title":"TBD"},{"location":"product/crossdb/","text":"Overview \u00b6 CrossDB(CDB) is a powerful high-performance distrubuted embedded SQL RDBMS database. It's developed to improve development efficiency for embedded programmers. CrossDB combines on-disk and in-memory data storage in a single embedded database system, so developers can optimize applications for speed and persistence, giving you flexibility to prioritize between performance, cost, power, and space-conserving storage options. Offering native and SQL APIs for C, C++, and Python. Feature List \u00b6 You can use CDB RDBMS to Manage Program Data efficiently. You can use CDB transaction to do persistency storage on Disk/Flash with ACID feature. YOu can use CDB to support Process Restartability, In-Service Software Upgrade(ISSU) easily. You can use CDB RDBMS to refactor your code conveniently. You can use CDB Index to optimize performance without changing your code. You can use CDB Trigger to implement Data-Driven programming paradigm. You can use CDB PUBSUB to subscribe DB from other process's DB either on same host or remote host. You can use CDB to implement Centralize-DB programming paradigm. You can use CDB eventloop to implement event-driven programming paradigm. You can use CDB RPC to build distributed service. You can use CDB CLI tool to debug running program's data in off-line way. You can use CDB SQL to view/create/update/delete/filter program data. You can use CDB Browser to view program data. You can use CDB to do DB backup restore it. You can use CDB DB Change Log to view DB change history with filter, backtrace, rate-limit, expiring, etc. You can use Python connector to write unit test with SQL to test program. You can copy the DB folders from device and open on PC/Server with cdb-cli or Python directly. Use CDB DB-Driven Mode to Build Program Logic (Table Trigger, FK, auto delete, Cascade Trigger) Use CDB Python Connector to do DB-Driven Unit Test Use CDB Pub/Sub to Build Distributed System (Eventloop/Timer/WorkQueue, vs IPC, OOP [priv data]) Use CDB Pub/Sub to Build Centralized DB-Driven System (3 rd lang, DM no checkpoint) CDB Serialization and RPC CDB SQL Connectors (RESP3, Python) CDB SQL Drivers (C, Python)","title":"CrossDB"},{"location":"product/crossdb/#overview","text":"CrossDB(CDB) is a powerful high-performance distrubuted embedded SQL RDBMS database. It's developed to improve development efficiency for embedded programmers. CrossDB combines on-disk and in-memory data storage in a single embedded database system, so developers can optimize applications for speed and persistence, giving you flexibility to prioritize between performance, cost, power, and space-conserving storage options. Offering native and SQL APIs for C, C++, and Python.","title":"Overview"},{"location":"product/crossdb/#feature-list","text":"You can use CDB RDBMS to Manage Program Data efficiently. You can use CDB transaction to do persistency storage on Disk/Flash with ACID feature. YOu can use CDB to support Process Restartability, In-Service Software Upgrade(ISSU) easily. You can use CDB RDBMS to refactor your code conveniently. You can use CDB Index to optimize performance without changing your code. You can use CDB Trigger to implement Data-Driven programming paradigm. You can use CDB PUBSUB to subscribe DB from other process's DB either on same host or remote host. You can use CDB to implement Centralize-DB programming paradigm. You can use CDB eventloop to implement event-driven programming paradigm. You can use CDB RPC to build distributed service. You can use CDB CLI tool to debug running program's data in off-line way. You can use CDB SQL to view/create/update/delete/filter program data. You can use CDB Browser to view program data. You can use CDB to do DB backup restore it. You can use CDB DB Change Log to view DB change history with filter, backtrace, rate-limit, expiring, etc. You can use Python connector to write unit test with SQL to test program. You can copy the DB folders from device and open on PC/Server with cdb-cli or Python directly. Use CDB DB-Driven Mode to Build Program Logic (Table Trigger, FK, auto delete, Cascade Trigger) Use CDB Python Connector to do DB-Driven Unit Test Use CDB Pub/Sub to Build Distributed System (Eventloop/Timer/WorkQueue, vs IPC, OOP [priv data]) Use CDB Pub/Sub to Build Centralized DB-Driven System (3 rd lang, DM no checkpoint) CDB Serialization and RPC CDB SQL Connectors (RESP3, Python) CDB SQL Drivers (C, Python)","title":"Feature List"},{"location":"pubsub/overview/","text":"Overview \u00b6 Client \u00b6 Python \u00b6 Troubleshooting \u00b6 telnet \u00b6 cdb-cli \u00b6","title":"Overview"},{"location":"pubsub/overview/#overview","text":"","title":"Overview"},{"location":"pubsub/overview/#client","text":"","title":"Client"},{"location":"pubsub/overview/#python","text":"","title":"Python"},{"location":"pubsub/overview/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"pubsub/overview/#telnet","text":"","title":"telnet"},{"location":"pubsub/overview/#cdb-cli","text":"","title":"cdb-cli"},{"location":"pubsub/pubsub-model/","text":"PubSub MOdel \u00b6 Concept and Model \u00b6 Architecture \u00b6 Incremental Sync \u00b6 Basic subscrition \u00b6 Cascading/Hierachy subscrition \u00b6 Multiple nodes in one process \u00b6 Bi-directional subscrition \u00b6 Multiple-Source subscrition \u00b6","title":"PubSub MOdel"},{"location":"pubsub/pubsub-model/#pubsub-model","text":"","title":"PubSub MOdel"},{"location":"pubsub/pubsub-model/#concept-and-model","text":"","title":"Concept and Model"},{"location":"pubsub/pubsub-model/#architecture","text":"","title":"Architecture"},{"location":"pubsub/pubsub-model/#incremental-sync","text":"","title":"Incremental Sync"},{"location":"pubsub/pubsub-model/#basic-subscrition","text":"","title":"Basic subscrition"},{"location":"pubsub/pubsub-model/#cascadinghierachy-subscrition","text":"","title":"Cascading/Hierachy subscrition"},{"location":"pubsub/pubsub-model/#multiple-nodes-in-one-process","text":"","title":"Multiple nodes in one process"},{"location":"pubsub/pubsub-model/#bi-directional-subscrition","text":"","title":"Bi-directional subscrition"},{"location":"pubsub/pubsub-model/#multiple-source-subscrition","text":"","title":"Multiple-Source subscrition"},{"location":"pubsub/replication/","text":"Replication \u00b6 HA Replication \u00b6 Group Replication \u00b6","title":"Replication"},{"location":"pubsub/replication/#replication","text":"","title":"Replication"},{"location":"pubsub/replication/#ha-replication","text":"","title":"HA Replication"},{"location":"pubsub/replication/#group-replication","text":"","title":"Group Replication"},{"location":"pubsub/reverse-pubsub/","text":"Reverse subscrition \u00b6 Centralized DB \u00b6 Large-Scale Sysmtem subscrition \u00b6","title":"Reverse subscrition"},{"location":"pubsub/reverse-pubsub/#reverse-subscrition","text":"","title":"Reverse subscrition"},{"location":"pubsub/reverse-pubsub/#centralized-db","text":"","title":"Centralized DB"},{"location":"pubsub/reverse-pubsub/#large-scale-sysmtem-subscrition","text":"","title":"Large-Scale Sysmtem subscrition"},{"location":"rdbms/overview/","text":"Overview \u00b6 TBD \u00b6","title":"Overview"},{"location":"rdbms/overview/#overview","text":"","title":"Overview"},{"location":"rdbms/overview/#tbd","text":"","title":"TBD"},{"location":"rdbms/rdbms-model/","text":"RDBMS \u00b6 Architecuture \u00b6 DB \u00b6 Table \u00b6 Record \u00b6 Cursor \u00b6 Index \u00b6 Transaction \u00b6 Backup and Restore \u00b6 DB Upgrade \u00b6","title":"RDBMS"},{"location":"rdbms/rdbms-model/#rdbms","text":"","title":"RDBMS"},{"location":"rdbms/rdbms-model/#architecuture","text":"","title":"Architecuture"},{"location":"rdbms/rdbms-model/#db","text":"","title":"DB"},{"location":"rdbms/rdbms-model/#table","text":"","title":"Table"},{"location":"rdbms/rdbms-model/#record","text":"","title":"Record"},{"location":"rdbms/rdbms-model/#cursor","text":"","title":"Cursor"},{"location":"rdbms/rdbms-model/#index","text":"","title":"Index"},{"location":"rdbms/rdbms-model/#transaction","text":"","title":"Transaction"},{"location":"rdbms/rdbms-model/#backup-and-restore","text":"","title":"Backup and Restore"},{"location":"rdbms/rdbms-model/#db-upgrade","text":"","title":"DB Upgrade"},{"location":"rdbms/sql/","text":"SQL \u00b6 SQL API \u00b6 DB \u00b6 Table \u00b6 Index \u00b6 Insert \u00b6 Update \u00b6 Select \u00b6 Delete \u00b6 Truncate \u00b6 Join \u00b6","title":"SQL"},{"location":"rdbms/sql/#sql","text":"","title":"SQL"},{"location":"rdbms/sql/#sql-api","text":"","title":"SQL API"},{"location":"rdbms/sql/#db","text":"","title":"DB"},{"location":"rdbms/sql/#table","text":"","title":"Table"},{"location":"rdbms/sql/#index","text":"","title":"Index"},{"location":"rdbms/sql/#insert","text":"","title":"Insert"},{"location":"rdbms/sql/#update","text":"","title":"Update"},{"location":"rdbms/sql/#select","text":"","title":"Select"},{"location":"rdbms/sql/#delete","text":"","title":"Delete"},{"location":"rdbms/sql/#truncate","text":"","title":"Truncate"},{"location":"rdbms/sql/#join","text":"","title":"Join"},{"location":"rpc/Serailization/","text":"Serailization \u00b6 Schema \u00b6 Serailization \u00b6 Binary \u00b6","title":"Serailization"},{"location":"rpc/Serailization/#serailization","text":"","title":"Serailization"},{"location":"rpc/Serailization/#schema","text":"","title":"Schema"},{"location":"rpc/Serailization/#serailization_1","text":"","title":"Serailization"},{"location":"rpc/Serailization/#binary","text":"","title":"Binary"},{"location":"rpc/overview/","text":"Overview \u00b6 TBD \u00b6","title":"Overview"},{"location":"rpc/overview/#overview","text":"","title":"Overview"},{"location":"rpc/overview/#tbd","text":"","title":"TBD"},{"location":"rpc/rpc-model/","text":"RPC \u00b6 Architecture \u00b6 API \u00b6 Troulbeshooting \u00b6 RPC Trace \u00b6","title":"RPC"},{"location":"rpc/rpc-model/#rpc","text":"","title":"RPC"},{"location":"rpc/rpc-model/#architecture","text":"","title":"Architecture"},{"location":"rpc/rpc-model/#api","text":"","title":"API"},{"location":"rpc/rpc-model/#troulbeshooting","text":"","title":"Troulbeshooting"},{"location":"rpc/rpc-model/#rpc-trace","text":"","title":"RPC Trace"},{"location":"server/event-loop/","text":"Event loop \u00b6 Porting \u00b6","title":"Event loop"},{"location":"server/event-loop/#event-loop","text":"","title":"Event loop"},{"location":"server/event-loop/#porting","text":"","title":"Porting"},{"location":"server/overview/","text":"Server \u00b6 Telnet Server \u00b6 cdb-cli Server \u00b6 Event-loop \u00b6 Porting \u00b6 Python Connectr \u00b6 Web Server \u00b6 REST Server \u00b6","title":"Server"},{"location":"server/overview/#server","text":"","title":"Server"},{"location":"server/overview/#telnet-server","text":"","title":"Telnet Server"},{"location":"server/overview/#cdb-cli-server","text":"","title":"cdb-cli Server"},{"location":"server/overview/#event-loop","text":"","title":"Event-loop"},{"location":"server/overview/#porting","text":"","title":"Porting"},{"location":"server/overview/#python-connectr","text":"","title":"Python Connectr"},{"location":"server/overview/#web-server","text":"","title":"Web Server"},{"location":"server/overview/#rest-server","text":"","title":"REST Server"},{"location":"server/scheduler/","text":"Scheduler \u00b6 Timer \u00b6 FD \u00b6 Job \u00b6 RPC \u00b6 Web \u00b6 PUBSUB \u00b6 Troubleshooting \u00b6","title":"Scheduler"},{"location":"server/scheduler/#scheduler","text":"","title":"Scheduler"},{"location":"server/scheduler/#timer","text":"","title":"Timer"},{"location":"server/scheduler/#fd","text":"","title":"FD"},{"location":"server/scheduler/#job","text":"","title":"Job"},{"location":"server/scheduler/#rpc","text":"","title":"RPC"},{"location":"server/scheduler/#web","text":"","title":"Web"},{"location":"server/scheduler/#pubsub","text":"","title":"PUBSUB"},{"location":"server/scheduler/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"troubleshooting/db-log/","text":"DB Log \u00b6 DB Change Log \u00b6 DB User Log \u00b6","title":"DB Log"},{"location":"troubleshooting/db-log/#db-log","text":"","title":"DB Log"},{"location":"troubleshooting/db-log/#db-change-log","text":"","title":"DB Change Log"},{"location":"troubleshooting/db-log/#db-user-log","text":"","title":"DB User Log"},{"location":"troubleshooting/overview/","text":"Troubleshooting \u00b6 CDB staticstics \u00b6 Cursor leak detection \u00b6 Relay \u00b6 Common Issues \u00b6","title":"Troubleshooting"},{"location":"troubleshooting/overview/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"troubleshooting/overview/#cdb-staticstics","text":"","title":"CDB staticstics"},{"location":"troubleshooting/overview/#cursor-leak-detection","text":"","title":"Cursor leak detection"},{"location":"troubleshooting/overview/#relay","text":"","title":"Relay"},{"location":"troubleshooting/overview/#common-issues","text":"","title":"Common Issues"},{"location":"troubleshooting/shell/","text":"CLI \u00b6 Shell API \u00b6 CLI tool \u00b6 Remote Debug \u00b6 DB Debug \u00b6 Table Debug \u00b6 Index Debug \u00b6 FK and Trigger Debug \u00b6 Counter \u00b6 Performance \u00b6","title":"CLI"},{"location":"troubleshooting/shell/#cli","text":"","title":"CLI"},{"location":"troubleshooting/shell/#shell-api","text":"","title":"Shell API"},{"location":"troubleshooting/shell/#cli-tool","text":"","title":"CLI tool"},{"location":"troubleshooting/shell/#remote-debug","text":"","title":"Remote Debug"},{"location":"troubleshooting/shell/#db-debug","text":"","title":"DB Debug"},{"location":"troubleshooting/shell/#table-debug","text":"","title":"Table Debug"},{"location":"troubleshooting/shell/#index-debug","text":"","title":"Index Debug"},{"location":"troubleshooting/shell/#fk-and-trigger-debug","text":"","title":"FK and Trigger Debug"},{"location":"troubleshooting/shell/#counter","text":"","title":"Counter"},{"location":"troubleshooting/shell/#performance","text":"","title":"Performance"},{"location":"troubleshooting/web-gui/","text":"Web GUI \u00b6 GUI Usage \u00b6 NAT Access \u00b6","title":"Web GUI"},{"location":"troubleshooting/web-gui/#web-gui","text":"","title":"Web GUI"},{"location":"troubleshooting/web-gui/#gui-usage","text":"","title":"GUI Usage"},{"location":"troubleshooting/web-gui/#nat-access","text":"","title":"NAT Access"},{"location":"tutorial/getting-started/","text":"Getting Started \u00b6 int main ( int argc , char * argv []) { cdb_error ret ; pthread_t pid ; if ( argc < 2 ) { printf ( \"Add TCP port to /etc/services \\n \" ); printf ( \"Start publiser: %s node host \\n \" , argv [ 0 ]); printf ( \"Start subscriber: %s node host pubnode pubhost \\n \" , argv [ 0 ]); printf ( \"Insert 1000 record into node's mac talbe: %s node @m1000 \\n \" , argv [ 0 ]); printf ( \"Insert 1000 record into node's route talbe: %s node @r1000 \\n \" , argv [ 0 ]); printf ( \"Insert 1000 record into node's arp talbe: %s node @a1000 \\n \" , argv [ 0 ]); return -1 ; } if ( argc > 1 ) strcpy ( g_node , argv [ 1 ]); if ( argc > 2 ) strcpy ( g_host , argv [ 2 ]); cdb_signal_register ( SIGSEGV ); dl_init_daemon_context (); dl_cdb_init (); // Create DB and Tables fisrt fib_db_init ( g_node ); uint32_t ts_beg = time ( NULL ); srand ( time ( NULL )); char * l3if [] = { \"v100\" , \"1.x1\" , \"lo1\" , \"v200\" , \"1.x2\" , \"lo2\" , \"v300\" , \"1.x3\" }; if (( 3 == argc ) && ( '@' == argv [ 2 ][ 0 ]) && ( 'm' == argv [ 2 ][ 1 ])) { mac_t mac = {}; int count = atoi ( & argv [ 2 ][ 2 ]), fail = 0 ; char buf [ 1024 ]; cdb_error ret ; uint64_t ts = cdb_timestamp_us (); for ( int i = 0 ; i < count ; i ++ ) { #if 0 sprintf (buf, \"replace into mact set mac=00:00:00:%02x:%02x:%02x vlan=%d port=%d bStatic=%c\", rand()%256, rand()%256, rand()%256, rand () % 4094 + 1, rand () % 128 + 1, rand ()%2?'T':'F'); ret = cdb_sql_execute2 (&g_hDb, CDB_DUMP_FLAG_IGNORE_FLDERR|CDB_DUMP_FLAG_QUITE|CDB_DUMP_FLAG_NO_PRIVATE, NULL, NULL, buf); #else mac . mac [ 3 ] = rand (); mac . mac [ 4 ] = rand (); mac . mac [ 5 ] = rand (); mac . vlan = rand () % 4094 + 1 ; mac . cvlan = rand () % 4094 + 1 ; mac . port = rand () % 128 + 1 ; mac . vsi = rand () % 0xff + 1 ; mac . logif = (( rand () % 0xf ) << 24 ) + ( rand () & 0xffff ); mac . timestamp = ts_beg + rand () % 100 ; mac . bStatic = rand () % 2 ; #if 1 //cdb_schema_print (cdb_table_get_schema(hMacTbl,0), NULL, 0, &mac, CDB_DUMP_RECORD); //printf (\"\\n\"); int len = cdb_record_dump2 ( hMacTbl , buf , sizeof ( buf ), CDB_DUMP_REPLACE , NULL , & mac , NULL , NULL , 0 , NULL , CDB_DUMP_FLAG_SQL | CDB_DUMP_FLAG_NO_ZERO | CDB_DUMP_FLAG_NO_PRIVATE | CDB_DUMP_FLAG_BINARY ); #if 0 mac_t key = {.vlan = 3333, .mac={0,0,0,0x11,0xd2,0xc3}}; mac_t mac2 = {.port = 111}; //mac.vlan = 2827; //int len = cdb_record_dump2 (hMacTbl, buf, sizeof(buf), CDB_DUMP_UPDATE, \"port\", &mac2, NULL, &key, 0, NULL, CDB_DUMP_FLAG_SQL | CDB_DUMP_FLAG_NO_ZERO | CDB_DUMP_FLAG_NO_PRIVATE | CDB_DUMP_FLAG_BINARY); int len = cdb_record_dump2 (hMacTbl, buf, sizeof(buf), CDB_DUMP_DELETE, NULL, &key, NULL, NULL, 0, NULL, CDB_DUMP_FLAG_SQL | CDB_DUMP_FLAG_NO_ZERO | CDB_DUMP_FLAG_NO_PRIVATE | CDB_DUMP_FLAG_BINARY); #endif ( void ) len ; ret = cdb_binrec_exec ( g_hDb , buf , 0 ); continue ; //cdb_schema_print (cdb_table_get_schema(hMacTbl,0), NULL, 0, &mac, CDB_DUMP_RECORD); //cdb_schema_dump2 (cdb_table_get_schema(hMacTbl,0), buf, sizeof(buf), CDB_DUMP_RECORD, &mac, CDB_DUMP_FLAG_NO_ZERO|CDB_DUMP_FLAG_BINARY); // cdb_schema_dump2 (cdb_table_get_schema(hMacTbl,0), buf, sizeof(buf), CDB_DUMP_RECORD, &mac, CDB_DUMP_FLAG_NO_ZERO); //memset (&mac, 0xcc, sizeof(mac)); // cdb_schema_scanf2 (cdb_table_get_schema(hMacTbl,0), buf, CDB_DUMP_RECORD, &mac, sizeof(mac), CDB_DUMP_FLAG_IGNORE_FLDERR|CDB_DUMP_FLAG_MEMSET); //cdb_schema_print (cdb_table_get_schema(hMacTbl,0), NULL, 0, &mac, CDB_DUMP_RECORD); #endif #endif ret = cdb_record_insert ( hMacTbl , & mac , NULL , NULL , 0 ); if ( ret != CDB_ERROR_OK ) { fail ++ ; } } ts = cdb_timestamp_us () - ts ; if ( 0 == ts ) { ts = 1 ; } printf ( \"insert %d mac, fail %d, use time %ds%dms%dus, TPS %d \\n \" , count , fail , ( int )( ts / 1000000 ), ( int )(( ts / 1000 ) % 1000 ), ( int )( ts % 1000 ), ( int )(( int64_t ) count * 1000000 / ts )); cdb_shell_loop ( NULL , NULL , NULL ); ( void ) buf ; return 0 ; } if (( 3 == argc ) && ( '@' == argv [ 2 ][ 0 ]) && ( 'r' == argv [ 2 ][ 1 ])) { route_t route = {}; int count = atoi ( & argv [ 2 ][ 2 ]), fail = 0 ; cdb_error ret ; for ( int i = 0 ; i < count ; i ++ ) { route . vrf = rand (); route . ip = rand () + 1 ; route . mask = ( rand () % 4 ) * 4 + 16 ; route . gw = rand () + 1 ; route . metric = rand (); route . type = rand () % 4 ; route . port = rand (); strcpy ( route . l3if , l3if [ rand () % 8 ]); ret = cdb_record_insert ( hRouteTbl , & route , NULL , NULL , 0 ); if ( ret != CDB_ERROR_OK ) { fail ++ ; } } printf ( \"insert %d route, fail %d \\n \" , count , fail ); cdb_shell_loop ( NULL , NULL , NULL ); return 0 ; } if (( 3 == argc ) && ( '@' == argv [ 2 ][ 0 ]) && ( 'a' == argv [ 2 ][ 1 ])) { arp_t arp = {}; int count = atoi ( & argv [ 2 ][ 2 ]), fail = 0 ; cdb_error ret ; for ( int i = 0 ; i < count ; i ++ ) { arp . vrf = rand (); arp . ip = rand () + 1 ; arp . mac [ 3 ] = rand (); arp . mac [ 4 ] = rand (); arp . mac [ 5 ] = rand (); arp . port = rand () % 128 + 1 ; strcpy ( arp . l3if , l3if [ rand () % 8 ]); arp . bStatic = rand () % 2 ; arp . flags = rand (); arp . hwtype = rand (); ret = cdb_record_insert ( hArpTbl , & arp , NULL , NULL , 0 ); if ( ret != CDB_ERROR_OK ) { fail ++ ; } } printf ( \"insert %d route, fail %d \\n \" , count , fail ); cdb_shell_loop ( NULL , NULL , NULL ); return 0 ; } printf ( \"mate card: %s \\n \" , dl_card_get_mate_card_str ()); if ( argc <= 3 ) { // Publisher only, run in default main thread eventloop cdb_pubsub_init ( NULL , NULL , NULL , NULL , NULL ); s_my_hEvtLoop = cdb_eventloop_get ( NULL , NULL ); #if 0 void *pTimer = cdb_eventloop_timer_create (s_my_hEvtLoop); if (NULL == pTimer) { printf (\"Failed to create timer\\n\"); return -1; } cdb_eventloop_timer_start (s_my_hEvtLoop, pTimer, 5, 0, pub_timer_cb, pTimer); #endif #if 0 cdb_pub_h hPub = cdb_publication_get (\"Hal\", NULL, \"Hal\", NULL); if (NULL != hPub) { cdb_pubsub_sync (hPub, NULL, CDB_SYNC_CHECK, my_pub_cb, hPub, 0); } #endif } else { // Publisher & Subscriber cdb_pub_h hPub ; const char * pubnode = argv [ 3 ]; const char * pubhost = argc > 4 ? argv [ 4 ] : NULL ; // NULL means local const char * pubdb = pubnode ; const char * subdb = g_node ; const char * pubname = g_node ; /* Init pubsub, run publisher and subscriber in default main event loop (NULL) or new oshal event loop if cdb_pubsub_init is called in thread which has no main event loop, must give an eventloop name */ const char * dftevtloop = \"oshal\" ; // NULL cdb_pubsub_init ( NULL , NULL , NULL , dftevtloop , dftevtloop ); if ( argc <= 6 ) { // Get default event loop s_my_hEvtLoop = cdb_eventloop_get ( dftevtloop , NULL ); if ( NULL == s_my_hEvtLoop ) { printf ( \"Failed to get eventloop \\n \" ); return -1 ; } // Create Publication ret = cdb_pubsub_create ( & hPub , pubnode , pubhost , pubname , NULL , pubdb , subdb , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to create publication %s \\n \" , cdb_errmsg ( ret )); return -1 ; } // Create Subscriptions cdb_bool bFilter = 0 ; ret = cdb_pubsub_subscribe ( hPub , \"mact\" , \"mact\" , \"mact\" , ! bFilter ? NULL : \"vlan=100\" , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"mact\" , cdb_errmsg ( ret )); } ret = cdb_pubsub_subscribe ( hPub , \"arp\" , \"arp\" , \"arp\" , NULL , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"arp\" , cdb_errmsg ( ret )); } ret = cdb_pubsub_subscribe ( hPub , \"route\" , \"route\" , \"route\" , ! bFilter ? NULL : \"hostOnly!='T'\" , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"mact\" , cdb_errmsg ( ret )); } ret = cdb_pubsub_subscribe ( hPub , \"salready\" , \"salready\" , \"salready\" , NULL , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"salready\" , cdb_errmsg ( ret )); } s_my_hPub = hPub ; //cdb_eventloop_addfd (s_my_hEvtLoop, fd, CPE_READABLE, my_fd_cb, NULL); #if 0 void *pTimer = cdb_eventloop_timer_create (s_my_hEvtLoop); if (NULL == pTimer) { printf (\"Failed to create timer\\n\"); return -1; } cdb_eventloop_timer_start (s_my_hEvtLoop, pTimer, 20, 0, sub_timer_cb, pTimer); #endif printf ( \"Begin sync ... \\n \" ); if (( argc > 5 ) && ( 'A' == argv [ 5 ][ 0 ])) { printf ( \"I'm Active, don't sync data from standby ... \\n \" ); ret = cdb_pubsub_sync ( hPub , NULL , CDB_SYNC_STOP , my_sub_cb , hPub , 0 ); } else { if ( argc > 5 ) { printf ( \"I'm Standby, sync with active ... \\n \" ); } cdb_pubsub_sync ( hPub , NULL , CDB_SYNC_FULL , my_sub_cb , hPub , 0 ); #if 0 cdb_trigger_create2 (hMacTbl, \"trig_ins\", CDB_TRIG_AFT_INSERT, mac_trigger, NULL, 0); cdb_trigger_create2 (hMacTbl, \"trig_del\", CDB_TRIG_AFT_DELETE, mac_trigger, NULL, 0); cdb_trigger_create2 (hMacTbl, \"trig_upd\", CDB_TRIG_AFT_UPDATE, mac_trigger, NULL, 0); #endif } } } // Create shell thread pthread_create ( & pid , NULL , shell_thread , NULL ); pthread_detach ( pid ); // Main Event Loop while ( ! s_bailout ) { dl_poll_fds ( -1 ); } return 0 ; } TBD \u00b6","title":"Getting Started"},{"location":"tutorial/getting-started/#getting-started","text":"int main ( int argc , char * argv []) { cdb_error ret ; pthread_t pid ; if ( argc < 2 ) { printf ( \"Add TCP port to /etc/services \\n \" ); printf ( \"Start publiser: %s node host \\n \" , argv [ 0 ]); printf ( \"Start subscriber: %s node host pubnode pubhost \\n \" , argv [ 0 ]); printf ( \"Insert 1000 record into node's mac talbe: %s node @m1000 \\n \" , argv [ 0 ]); printf ( \"Insert 1000 record into node's route talbe: %s node @r1000 \\n \" , argv [ 0 ]); printf ( \"Insert 1000 record into node's arp talbe: %s node @a1000 \\n \" , argv [ 0 ]); return -1 ; } if ( argc > 1 ) strcpy ( g_node , argv [ 1 ]); if ( argc > 2 ) strcpy ( g_host , argv [ 2 ]); cdb_signal_register ( SIGSEGV ); dl_init_daemon_context (); dl_cdb_init (); // Create DB and Tables fisrt fib_db_init ( g_node ); uint32_t ts_beg = time ( NULL ); srand ( time ( NULL )); char * l3if [] = { \"v100\" , \"1.x1\" , \"lo1\" , \"v200\" , \"1.x2\" , \"lo2\" , \"v300\" , \"1.x3\" }; if (( 3 == argc ) && ( '@' == argv [ 2 ][ 0 ]) && ( 'm' == argv [ 2 ][ 1 ])) { mac_t mac = {}; int count = atoi ( & argv [ 2 ][ 2 ]), fail = 0 ; char buf [ 1024 ]; cdb_error ret ; uint64_t ts = cdb_timestamp_us (); for ( int i = 0 ; i < count ; i ++ ) { #if 0 sprintf (buf, \"replace into mact set mac=00:00:00:%02x:%02x:%02x vlan=%d port=%d bStatic=%c\", rand()%256, rand()%256, rand()%256, rand () % 4094 + 1, rand () % 128 + 1, rand ()%2?'T':'F'); ret = cdb_sql_execute2 (&g_hDb, CDB_DUMP_FLAG_IGNORE_FLDERR|CDB_DUMP_FLAG_QUITE|CDB_DUMP_FLAG_NO_PRIVATE, NULL, NULL, buf); #else mac . mac [ 3 ] = rand (); mac . mac [ 4 ] = rand (); mac . mac [ 5 ] = rand (); mac . vlan = rand () % 4094 + 1 ; mac . cvlan = rand () % 4094 + 1 ; mac . port = rand () % 128 + 1 ; mac . vsi = rand () % 0xff + 1 ; mac . logif = (( rand () % 0xf ) << 24 ) + ( rand () & 0xffff ); mac . timestamp = ts_beg + rand () % 100 ; mac . bStatic = rand () % 2 ; #if 1 //cdb_schema_print (cdb_table_get_schema(hMacTbl,0), NULL, 0, &mac, CDB_DUMP_RECORD); //printf (\"\\n\"); int len = cdb_record_dump2 ( hMacTbl , buf , sizeof ( buf ), CDB_DUMP_REPLACE , NULL , & mac , NULL , NULL , 0 , NULL , CDB_DUMP_FLAG_SQL | CDB_DUMP_FLAG_NO_ZERO | CDB_DUMP_FLAG_NO_PRIVATE | CDB_DUMP_FLAG_BINARY ); #if 0 mac_t key = {.vlan = 3333, .mac={0,0,0,0x11,0xd2,0xc3}}; mac_t mac2 = {.port = 111}; //mac.vlan = 2827; //int len = cdb_record_dump2 (hMacTbl, buf, sizeof(buf), CDB_DUMP_UPDATE, \"port\", &mac2, NULL, &key, 0, NULL, CDB_DUMP_FLAG_SQL | CDB_DUMP_FLAG_NO_ZERO | CDB_DUMP_FLAG_NO_PRIVATE | CDB_DUMP_FLAG_BINARY); int len = cdb_record_dump2 (hMacTbl, buf, sizeof(buf), CDB_DUMP_DELETE, NULL, &key, NULL, NULL, 0, NULL, CDB_DUMP_FLAG_SQL | CDB_DUMP_FLAG_NO_ZERO | CDB_DUMP_FLAG_NO_PRIVATE | CDB_DUMP_FLAG_BINARY); #endif ( void ) len ; ret = cdb_binrec_exec ( g_hDb , buf , 0 ); continue ; //cdb_schema_print (cdb_table_get_schema(hMacTbl,0), NULL, 0, &mac, CDB_DUMP_RECORD); //cdb_schema_dump2 (cdb_table_get_schema(hMacTbl,0), buf, sizeof(buf), CDB_DUMP_RECORD, &mac, CDB_DUMP_FLAG_NO_ZERO|CDB_DUMP_FLAG_BINARY); // cdb_schema_dump2 (cdb_table_get_schema(hMacTbl,0), buf, sizeof(buf), CDB_DUMP_RECORD, &mac, CDB_DUMP_FLAG_NO_ZERO); //memset (&mac, 0xcc, sizeof(mac)); // cdb_schema_scanf2 (cdb_table_get_schema(hMacTbl,0), buf, CDB_DUMP_RECORD, &mac, sizeof(mac), CDB_DUMP_FLAG_IGNORE_FLDERR|CDB_DUMP_FLAG_MEMSET); //cdb_schema_print (cdb_table_get_schema(hMacTbl,0), NULL, 0, &mac, CDB_DUMP_RECORD); #endif #endif ret = cdb_record_insert ( hMacTbl , & mac , NULL , NULL , 0 ); if ( ret != CDB_ERROR_OK ) { fail ++ ; } } ts = cdb_timestamp_us () - ts ; if ( 0 == ts ) { ts = 1 ; } printf ( \"insert %d mac, fail %d, use time %ds%dms%dus, TPS %d \\n \" , count , fail , ( int )( ts / 1000000 ), ( int )(( ts / 1000 ) % 1000 ), ( int )( ts % 1000 ), ( int )(( int64_t ) count * 1000000 / ts )); cdb_shell_loop ( NULL , NULL , NULL ); ( void ) buf ; return 0 ; } if (( 3 == argc ) && ( '@' == argv [ 2 ][ 0 ]) && ( 'r' == argv [ 2 ][ 1 ])) { route_t route = {}; int count = atoi ( & argv [ 2 ][ 2 ]), fail = 0 ; cdb_error ret ; for ( int i = 0 ; i < count ; i ++ ) { route . vrf = rand (); route . ip = rand () + 1 ; route . mask = ( rand () % 4 ) * 4 + 16 ; route . gw = rand () + 1 ; route . metric = rand (); route . type = rand () % 4 ; route . port = rand (); strcpy ( route . l3if , l3if [ rand () % 8 ]); ret = cdb_record_insert ( hRouteTbl , & route , NULL , NULL , 0 ); if ( ret != CDB_ERROR_OK ) { fail ++ ; } } printf ( \"insert %d route, fail %d \\n \" , count , fail ); cdb_shell_loop ( NULL , NULL , NULL ); return 0 ; } if (( 3 == argc ) && ( '@' == argv [ 2 ][ 0 ]) && ( 'a' == argv [ 2 ][ 1 ])) { arp_t arp = {}; int count = atoi ( & argv [ 2 ][ 2 ]), fail = 0 ; cdb_error ret ; for ( int i = 0 ; i < count ; i ++ ) { arp . vrf = rand (); arp . ip = rand () + 1 ; arp . mac [ 3 ] = rand (); arp . mac [ 4 ] = rand (); arp . mac [ 5 ] = rand (); arp . port = rand () % 128 + 1 ; strcpy ( arp . l3if , l3if [ rand () % 8 ]); arp . bStatic = rand () % 2 ; arp . flags = rand (); arp . hwtype = rand (); ret = cdb_record_insert ( hArpTbl , & arp , NULL , NULL , 0 ); if ( ret != CDB_ERROR_OK ) { fail ++ ; } } printf ( \"insert %d route, fail %d \\n \" , count , fail ); cdb_shell_loop ( NULL , NULL , NULL ); return 0 ; } printf ( \"mate card: %s \\n \" , dl_card_get_mate_card_str ()); if ( argc <= 3 ) { // Publisher only, run in default main thread eventloop cdb_pubsub_init ( NULL , NULL , NULL , NULL , NULL ); s_my_hEvtLoop = cdb_eventloop_get ( NULL , NULL ); #if 0 void *pTimer = cdb_eventloop_timer_create (s_my_hEvtLoop); if (NULL == pTimer) { printf (\"Failed to create timer\\n\"); return -1; } cdb_eventloop_timer_start (s_my_hEvtLoop, pTimer, 5, 0, pub_timer_cb, pTimer); #endif #if 0 cdb_pub_h hPub = cdb_publication_get (\"Hal\", NULL, \"Hal\", NULL); if (NULL != hPub) { cdb_pubsub_sync (hPub, NULL, CDB_SYNC_CHECK, my_pub_cb, hPub, 0); } #endif } else { // Publisher & Subscriber cdb_pub_h hPub ; const char * pubnode = argv [ 3 ]; const char * pubhost = argc > 4 ? argv [ 4 ] : NULL ; // NULL means local const char * pubdb = pubnode ; const char * subdb = g_node ; const char * pubname = g_node ; /* Init pubsub, run publisher and subscriber in default main event loop (NULL) or new oshal event loop if cdb_pubsub_init is called in thread which has no main event loop, must give an eventloop name */ const char * dftevtloop = \"oshal\" ; // NULL cdb_pubsub_init ( NULL , NULL , NULL , dftevtloop , dftevtloop ); if ( argc <= 6 ) { // Get default event loop s_my_hEvtLoop = cdb_eventloop_get ( dftevtloop , NULL ); if ( NULL == s_my_hEvtLoop ) { printf ( \"Failed to get eventloop \\n \" ); return -1 ; } // Create Publication ret = cdb_pubsub_create ( & hPub , pubnode , pubhost , pubname , NULL , pubdb , subdb , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to create publication %s \\n \" , cdb_errmsg ( ret )); return -1 ; } // Create Subscriptions cdb_bool bFilter = 0 ; ret = cdb_pubsub_subscribe ( hPub , \"mact\" , \"mact\" , \"mact\" , ! bFilter ? NULL : \"vlan=100\" , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"mact\" , cdb_errmsg ( ret )); } ret = cdb_pubsub_subscribe ( hPub , \"arp\" , \"arp\" , \"arp\" , NULL , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"arp\" , cdb_errmsg ( ret )); } ret = cdb_pubsub_subscribe ( hPub , \"route\" , \"route\" , \"route\" , ! bFilter ? NULL : \"hostOnly!='T'\" , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"mact\" , cdb_errmsg ( ret )); } ret = cdb_pubsub_subscribe ( hPub , \"salready\" , \"salready\" , \"salready\" , NULL , NULL , 0 ); if ( CDB_ERROR_OK != ret ) { printf ( \"Failed to subscribe %s %s \\n \" , \"salready\" , cdb_errmsg ( ret )); } s_my_hPub = hPub ; //cdb_eventloop_addfd (s_my_hEvtLoop, fd, CPE_READABLE, my_fd_cb, NULL); #if 0 void *pTimer = cdb_eventloop_timer_create (s_my_hEvtLoop); if (NULL == pTimer) { printf (\"Failed to create timer\\n\"); return -1; } cdb_eventloop_timer_start (s_my_hEvtLoop, pTimer, 20, 0, sub_timer_cb, pTimer); #endif printf ( \"Begin sync ... \\n \" ); if (( argc > 5 ) && ( 'A' == argv [ 5 ][ 0 ])) { printf ( \"I'm Active, don't sync data from standby ... \\n \" ); ret = cdb_pubsub_sync ( hPub , NULL , CDB_SYNC_STOP , my_sub_cb , hPub , 0 ); } else { if ( argc > 5 ) { printf ( \"I'm Standby, sync with active ... \\n \" ); } cdb_pubsub_sync ( hPub , NULL , CDB_SYNC_FULL , my_sub_cb , hPub , 0 ); #if 0 cdb_trigger_create2 (hMacTbl, \"trig_ins\", CDB_TRIG_AFT_INSERT, mac_trigger, NULL, 0); cdb_trigger_create2 (hMacTbl, \"trig_del\", CDB_TRIG_AFT_DELETE, mac_trigger, NULL, 0); cdb_trigger_create2 (hMacTbl, \"trig_upd\", CDB_TRIG_AFT_UPDATE, mac_trigger, NULL, 0); #endif } } } // Create shell thread pthread_create ( & pid , NULL , shell_thread , NULL ); pthread_detach ( pid ); // Main Event Loop while ( ! s_bailout ) { dl_poll_fds ( -1 ); } return 0 ; }","title":"Getting Started"},{"location":"tutorial/getting-started/#tbd","text":"","title":"TBD"},{"location":"tutorial/introduction/","text":"Introduction \u00b6 CrossDB(CDB) is a powerful high-performance distrubuted embedded SQL RDBMS database. It's developed to improve development efficiency for embedded programmers. You can use CDB RDBMS to Manage Program Data efficiently. You can use CDB transaction to do persistency storage on Disk/Flash with ACID feature. YOu can use CDB to support Process Restartability, In-Service Software Upgrade(ISSU) easily. You can use CDB RDBMS to refactor your code conveniently. You can use CDB Index to optimize performance without changing your code. You can use CDB Trigger to implement Data-Driven programming paradigm. You can use CDB PUBSUB to subscribe DB from other process's DB either on same host or remote host. You can use CDB to implement Centralize-DB programming paradigm. You can use CDB eventloop to implement event-driven programming paradigm. You can use CDB RPC to build distributed service. You can use CDB CLI tool to debug running program's data in off-line way. You can use CDB SQL to view/create/update/delete/filter program data. You can use CDB Browser to view program data. You can use CDB to do DB backup restore it. You can use CDB DB Change Log to view DB change history with filter, backtrace, rate-limit, expiring, etc. You can use Python connector to write unit test with SQL to test program. You can copy the DB folders from device and open on PC/Server with cdb-cli or Python directly. Use CDB DB-Driven Mode to Build Program Logic (Table Trigger, FK, auto delete, Cascade Trigger) Use CDB Python Connector to do DB-Driven Unit Test Use CDB Pub/Sub to Build Distributed System (Eventloop/Timer/WorkQueue, vs IPC, OOP [priv data]) Use CDB Pub/Sub to Build Centralized DB-Driven System (3 rd lang, DM no checkpoint) CDB Serialization and RPC CDB SQL Connectors (RESP3, Python) CDB SQL Drivers (C, Python) Architecture \u00b6 Feature List \u00b6 TDB Support OS \u00b6 Linux Windows Support Platform \u00b6 Following platform are tested x86 PowerPC ARM Porting \u00b6 Log Heart beat Compiling \u00b6 Linux \u00b6 Build library Build example Windows \u00b6 You can build with MinGW or MSYS2 or Cygwin Build library MinGW MSYS2 Cygwin Build example","title":"Introduction"},{"location":"tutorial/introduction/#introduction","text":"CrossDB(CDB) is a powerful high-performance distrubuted embedded SQL RDBMS database. It's developed to improve development efficiency for embedded programmers. You can use CDB RDBMS to Manage Program Data efficiently. You can use CDB transaction to do persistency storage on Disk/Flash with ACID feature. YOu can use CDB to support Process Restartability, In-Service Software Upgrade(ISSU) easily. You can use CDB RDBMS to refactor your code conveniently. You can use CDB Index to optimize performance without changing your code. You can use CDB Trigger to implement Data-Driven programming paradigm. You can use CDB PUBSUB to subscribe DB from other process's DB either on same host or remote host. You can use CDB to implement Centralize-DB programming paradigm. You can use CDB eventloop to implement event-driven programming paradigm. You can use CDB RPC to build distributed service. You can use CDB CLI tool to debug running program's data in off-line way. You can use CDB SQL to view/create/update/delete/filter program data. You can use CDB Browser to view program data. You can use CDB to do DB backup restore it. You can use CDB DB Change Log to view DB change history with filter, backtrace, rate-limit, expiring, etc. You can use Python connector to write unit test with SQL to test program. You can copy the DB folders from device and open on PC/Server with cdb-cli or Python directly. Use CDB DB-Driven Mode to Build Program Logic (Table Trigger, FK, auto delete, Cascade Trigger) Use CDB Python Connector to do DB-Driven Unit Test Use CDB Pub/Sub to Build Distributed System (Eventloop/Timer/WorkQueue, vs IPC, OOP [priv data]) Use CDB Pub/Sub to Build Centralized DB-Driven System (3 rd lang, DM no checkpoint) CDB Serialization and RPC CDB SQL Connectors (RESP3, Python) CDB SQL Drivers (C, Python)","title":"Introduction"},{"location":"tutorial/introduction/#architecture","text":"","title":"Architecture"},{"location":"tutorial/introduction/#feature-list","text":"TDB","title":"Feature List"},{"location":"tutorial/introduction/#support-os","text":"Linux Windows","title":"Support OS"},{"location":"tutorial/introduction/#support-platform","text":"Following platform are tested x86 PowerPC ARM","title":"Support Platform"},{"location":"tutorial/introduction/#porting","text":"Log Heart beat","title":"Porting"},{"location":"tutorial/introduction/#compiling","text":"","title":"Compiling"},{"location":"tutorial/introduction/#linux","text":"Build library Build example","title":"Linux"},{"location":"tutorial/introduction/#windows","text":"You can build with MinGW or MSYS2 or Cygwin Build library MinGW MSYS2 Cygwin Build example","title":"Windows"}]}